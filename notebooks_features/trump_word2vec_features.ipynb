{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from project_helper import TweetData\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = TweetData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_tweets = tweet_data.clean_tweets #[pd.to_datetime(tweet_data.clean_tweets.after4_date)\n",
    "                                       #<= pd.to_datetime(daily_df.index[-1])]\n",
    "daily_tweets.after4_date = pd.to_datetime(daily_tweets.after4_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>after4_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:57:12-06:00</th>\n",
       "      <td>tell jennifer williams whoever that is to read...</td>\n",
       "      <td>2019-11-17 19:57:12-06:00</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:56:02-06:00</th>\n",
       "      <td></td>\n",
       "      <td>2019-11-17 19:56:02-06:00</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:49:47-06:00</th>\n",
       "      <td>paul krugman of has been wrong about me from t...</td>\n",
       "      <td>2019-11-17 19:49:47-06:00</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:47:32-06:00</th>\n",
       "      <td>schiff is a corrupt politician</td>\n",
       "      <td>2019-11-17 19:47:32-06:00</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:30:09-06:00</th>\n",
       "      <td>blew the nasty amp obnoxious chris wallace wil...</td>\n",
       "      <td>2019-11-17 19:30:09-06:00</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      tweets  \\\n",
       "timestamp                                                                      \n",
       "2019-11-17 19:57:12-06:00  tell jennifer williams whoever that is to read...   \n",
       "2019-11-17 19:56:02-06:00                                                      \n",
       "2019-11-17 19:49:47-06:00  paul krugman of has been wrong about me from t...   \n",
       "2019-11-17 19:47:32-06:00                    schiff is a corrupt politician    \n",
       "2019-11-17 19:30:09-06:00  blew the nasty amp obnoxious chris wallace wil...   \n",
       "\n",
       "                                          timestamp after4_date  \n",
       "timestamp                                                        \n",
       "2019-11-17 19:57:12-06:00 2019-11-17 19:57:12-06:00  2019-11-18  \n",
       "2019-11-17 19:56:02-06:00 2019-11-17 19:56:02-06:00  2019-11-18  \n",
       "2019-11-17 19:49:47-06:00 2019-11-17 19:49:47-06:00  2019-11-18  \n",
       "2019-11-17 19:47:32-06:00 2019-11-17 19:47:32-06:00  2019-11-18  \n",
       "2019-11-17 19:30:09-06:00 2019-11-17 19:30:09-06:00  2019-11-18  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/trump_rnn_1911.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.in_embed.weight.to('cpu').data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4574, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trump_rnn_1702.net',\n",
       " 'trump_rnn_1703.net',\n",
       " 'trump_rnn_1908.net',\n",
       " 'trump_rnn_1707.net',\n",
       " 'trump_rnn_1712.net']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arches = os.listdir('models')\n",
    "arches[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = []\n",
    "for arch in arches:\n",
    "    model = torch.load('models/{}'.format(arch))\n",
    "    embedding_list.append(model.in_embed.weight.to('cpu').data.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2576, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TweetData('data/opt/trump_archive_db_1911.csv')\n",
    "words = data.words\n",
    "vocab_to_int, int_to_vocab = data.vocab_to_int, data.int_to_vocab\n",
    "int_words = data.int_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07983071,  0.13481925, -0.3339518 , ...,  0.07891949,\n",
       "        -0.03683575, -0.06613905],\n",
       "       [-0.4210904 ,  0.02706584, -0.1898706 , ..., -0.17446454,\n",
       "        -0.08358873, -0.03138035],\n",
       "       [-0.22094908, -0.20108747, -0.04167196, ...,  0.11216594,\n",
       "         0.00401473,  0.15296404],\n",
       "       ...,\n",
       "       [-0.38425526, -0.3069386 ,  0.7174769 , ..., -0.4966805 ,\n",
       "        -0.22396143, -0.90884376],\n",
       "       [-1.4828042 ,  0.38311642,  0.23013367, ...,  0.69838697,\n",
       "         0.10621499,  0.49422497],\n",
       "       [-0.72725123,  0.19940047, -0.78007627, ...,  0.00616149,\n",
       "         0.37083137, -0.43986282]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2019-11-17 19:57:12-06:00   2019-11-18\n",
       "2019-11-17 19:56:02-06:00   2019-11-18\n",
       "2019-11-17 19:49:47-06:00   2019-11-18\n",
       "2019-11-17 19:47:32-06:00   2019-11-18\n",
       "2019-11-17 19:30:09-06:00   2019-11-18\n",
       "                               ...    \n",
       "2009-05-12 14:07:28-05:00   2009-05-12\n",
       "2009-05-08 20:40:15-05:00   2009-05-09\n",
       "2009-05-08 13:38:08-05:00   2009-05-08\n",
       "2009-05-05 01:00:10-05:00   2009-05-05\n",
       "2009-05-04 18:54:02-05:00   2009-05-05\n",
       "Name: after4_date, Length: 28813, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_tweets.after4_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_embeddings = {}\n",
    "dtws = daily_tweets.tweets[daily_tweets.after4_date >= pd.to_datetime('1-1-2017')]\n",
    "tweet_embeddings_np = np.zeros([dtws.shape[0],100])\n",
    "\n",
    "for i, tweet in enumerate(dtws):\n",
    "    embed_sum = np.zeros(100) \n",
    "    tw = tweet.split()\n",
    "    wd_count = 0\n",
    "    for word in tw:\n",
    "        try:\n",
    "            if vocab_to_int[word] >= 25:\n",
    "                embed_sum += embedding_list[-1][vocab_to_int[word]]\n",
    "                wd_count += 1\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    if wd_count > 0:    \n",
    "        tweet_embeddings[i] = embed_sum/wd_count\n",
    "        tweet_embeddings_np[i,:] = embed_sum/wd_count\n",
    "    else:\n",
    "        tweet_embeddings[i] = embed_sum\n",
    "        tweet_embeddings_np[i,:] = embed_sum\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9582, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_embeddings_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tweet_embeddings_np).to_csv('tweet_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collusion\n",
      "democrats\n",
      "friday\n",
      "president\n",
      "up\n",
      "do\n",
      "has\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'democrats wrote to the ukrainian government in may urging it to continue investigations into president donald trumps alleged collusion with russia in the presidential campaign collusion later found not to exist '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = 1000\n",
    "\n",
    "embedding = model.in_embed\n",
    "embed_vectors = embedding.weight\n",
    "magnitudes = embed_vectors.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
    "tweet_after = daily_tweets.tweets[daily_tweets.after4_date >= pd.to_datetime('1-1-2017')]\n",
    "valid_vector = torch.FloatTensor(tweet_embeddings[tw])\n",
    "wds = (torch.matmul(valid_vector, embed_vectors.t()) / torch.FloatTensor(magnitudes)).topk(10)\n",
    "for wd in list(wds[1][0].numpy()):\n",
    "    if wd> 25 :\n",
    "        print(int_to_vocab[wd])\n",
    "tweet_after[tw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([[40.2167, 35.8954, 35.8427, 35.8403, 35.8321, 35.7682, 35.7297, 35.7110,\n",
      "         35.6348, 35.6074]]),\n",
      "indices=tensor([[1467, 6502, 6555, 1882, 1575, 3176, 5377, 2799, 1673, 6328]]))\n",
      "the federal reserve loves watching our manufacturers struggle with their exports to the benefit of other parts of the world has anyone looked at what almost all other countries are doing to take advantage of the good old usa our fed has been calling it wrong for too long \n",
      "\n",
      "the fake news is working overtime just reported that despite the tremendous success we are having with the economy amp all things else of the network news about me is negative fake why do we work so hard in working with the media when it is corrupt take away credentials \n",
      "\n",
      "delegation heading to china to begin talks on the massive trade deficit that has been created with our country very much like north korea this should have been fixed years ago not now same with other countries and nafta but it will all get done great potential for usa \n",
      "\n",
      "the e u and china will further lower interest rates and pump money into their systems making it much easier for their manufacturers to sell product in the meantime and with very low inflation our fed does nothing and probably will do very little by comparison too bad \n",
      "\n",
      "we are competing with many countries that have a far lower interest rate and we should be lower than them yesterday highest dollar in u s history no inflation wake up federal reserve such growth potential almost like never before \n",
      "\n",
      "the best thing ever to happen to twitter is donald trump so true but they dont treat me well as a republican very discriminatory hard for people to sign on constantly taking people off list big complaints from many people different names over m \n",
      "\n",
      "the hatred and extreme bias of me by has clouded their thinking and made them unable to function but actually as i have always said this has been going on for a long time little jeff z has done a terrible job his ratings suck amp at amp t should fire him to save credibility \n",
      "\n",
      "in a letter to her house colleagues nancy pelosi said president trump had a temper tantrum for us all to see this is not true i was purposely very polite and calm much as i was minutes later with the press in the rose garden can be easily proven it is all such a lie \n",
      "\n",
      "spread is way too much as other countries say thank you to clueless jay powell and the federal reserve germany and many others are playing the game crazy inverted yield curve we should easily be reaping big rewards amp gains but the fed is holding us back we will win \n",
      "\n",
      "there is no one better to represent the people of n y and staten island a place i know very well than who is strong on borders amp crime loves our military amp our vets voted for tax cuts and is helping me to make america great again dan has my full endorsement \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tw = 1467\n",
    "\n",
    "embedding = model.in_embed\n",
    "embed_vectors = torch.FloatTensor(tweet_embeddings_np)\n",
    "magnitudes = embed_vectors.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
    "tweet_after = daily_tweets.tweets[daily_tweets.after4_date >= pd.to_datetime('1-1-2017')]\n",
    "valid_vector = torch.FloatTensor(tweet_embeddings[tw])\n",
    "wds = (torch.matmul(valid_vector, embed_vectors.t()) / torch.FloatTensor(magnitudes))\n",
    "wds[wds != wds] = 0\n",
    "print(wds.topk(10))\n",
    "for i in wds.topk(10).indices.numpy():\n",
    "    for tweet_range in i:\n",
    "        print(tweet_after[tweet_range])\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweet_after[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_after[9335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_after[4955]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_after[2434]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs109]",
   "language": "python",
   "name": "conda-env-cs109-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
