{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from project_helper import TweetData\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = TweetData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_tweets = tweet_data.clean_tweets #[pd.to_datetime(tweet_data.clean_tweets.after4_date)\n",
    "                                       #<= pd.to_datetime(daily_df.index[-1])]\n",
    "daily_tweets.after4_date = pd.to_datetime(daily_tweets.after4_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>after4_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:57:12-06:00</th>\n",
       "      <td>tell jennifer williams whoever that is to read...</td>\n",
       "      <td>2019-11-17 19:57:12-06:00</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:56:02-06:00</th>\n",
       "      <td></td>\n",
       "      <td>2019-11-17 19:56:02-06:00</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:49:47-06:00</th>\n",
       "      <td>paul krugman of has been wrong about me from t...</td>\n",
       "      <td>2019-11-17 19:49:47-06:00</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:47:32-06:00</th>\n",
       "      <td>schiff is a corrupt politician</td>\n",
       "      <td>2019-11-17 19:47:32-06:00</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:30:09-06:00</th>\n",
       "      <td>blew the nasty amp obnoxious chris wallace wil...</td>\n",
       "      <td>2019-11-17 19:30:09-06:00</td>\n",
       "      <td>2019-11-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      tweets  \\\n",
       "timestamp                                                                      \n",
       "2019-11-17 19:57:12-06:00  tell jennifer williams whoever that is to read...   \n",
       "2019-11-17 19:56:02-06:00                                                      \n",
       "2019-11-17 19:49:47-06:00  paul krugman of has been wrong about me from t...   \n",
       "2019-11-17 19:47:32-06:00                    schiff is a corrupt politician    \n",
       "2019-11-17 19:30:09-06:00  blew the nasty amp obnoxious chris wallace wil...   \n",
       "\n",
       "                                          timestamp after4_date  \n",
       "timestamp                                                        \n",
       "2019-11-17 19:57:12-06:00 2019-11-17 19:57:12-06:00  2019-11-18  \n",
       "2019-11-17 19:56:02-06:00 2019-11-17 19:56:02-06:00  2019-11-18  \n",
       "2019-11-17 19:49:47-06:00 2019-11-17 19:49:47-06:00  2019-11-18  \n",
       "2019-11-17 19:47:32-06:00 2019-11-17 19:47:32-06:00  2019-11-18  \n",
       "2019-11-17 19:30:09-06:00 2019-11-17 19:30:09-06:00  2019-11-18  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/trump_rnn_1911.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.in_embed.weight.to('cpu').data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4574, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trump_rnn_1702.net',\n",
       " 'trump_rnn_1703.net',\n",
       " 'trump_rnn_1908.net',\n",
       " 'trump_rnn_1707.net',\n",
       " 'trump_rnn_1712.net']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arches = os.listdir('models')\n",
    "arches[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = []\n",
    "for arch in arches:\n",
    "    model = torch.load('models/{}'.format(arch))\n",
    "    embedding_list.append(model.in_embed.weight.to('cpu').data.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2576, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TweetData('data/opt/trump_archive_db_1911.csv')\n",
    "words = data.words\n",
    "vocab_to_int, int_to_vocab = data.vocab_to_int, data.int_to_vocab\n",
    "int_words = data.int_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07983071,  0.13481925, -0.3339518 , ...,  0.07891949,\n",
       "        -0.03683575, -0.06613905],\n",
       "       [-0.4210904 ,  0.02706584, -0.1898706 , ..., -0.17446454,\n",
       "        -0.08358873, -0.03138035],\n",
       "       [-0.22094908, -0.20108747, -0.04167196, ...,  0.11216594,\n",
       "         0.00401473,  0.15296404],\n",
       "       ...,\n",
       "       [-0.38425526, -0.3069386 ,  0.7174769 , ..., -0.4966805 ,\n",
       "        -0.22396143, -0.90884376],\n",
       "       [-1.4828042 ,  0.38311642,  0.23013367, ...,  0.69838697,\n",
       "         0.10621499,  0.49422497],\n",
       "       [-0.72725123,  0.19940047, -0.78007627, ...,  0.00616149,\n",
       "         0.37083137, -0.43986282]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2019-11-17 19:57:12-06:00     True\n",
       "2019-11-17 19:56:02-06:00     True\n",
       "2019-11-17 19:49:47-06:00     True\n",
       "2019-11-17 19:47:32-06:00     True\n",
       "2019-11-17 19:30:09-06:00     True\n",
       "                             ...  \n",
       "2009-05-12 14:07:28-05:00    False\n",
       "2009-05-08 20:40:15-05:00    False\n",
       "2009-05-08 13:38:08-05:00    False\n",
       "2009-05-05 01:00:10-05:00    False\n",
       "2009-05-04 18:54:02-05:00    False\n",
       "Name: after4_date, Length: 28813, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_tweets.after4_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_embeddings = {}\n",
    "dtws = daily_tweets.tweets[daily_tweets.after4_date >= pd.to_datetime('1-1-2017')]\n",
    "tweet_embeddings_np = np.zeros([dtws.shape[0],100])\n",
    "\n",
    "for i, tweet in enumerate(dtws):\n",
    "    embed_sum = np.zeros(100) \n",
    "    tw = tweet.split()\n",
    "    for word in tw:\n",
    "        try:\n",
    "            if vocab_to_int[word] >= 100:\n",
    "                embed_sum += embedding_list[-1][vocab_to_int[word]]\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    tweet_embeddings[i] = embed_sum\n",
    "    tweet_embeddings_np[i,:] = embed_sum\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.47077961, -1.99534133, -9.21356507, ...,  0.14838102,\n",
       "         5.38709498, -0.47451643],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-3.74675519,  0.21890989, -3.47137829, ...,  5.13478435,\n",
       "         2.4891945 ,  2.45625968],\n",
       "       ...,\n",
       "       [ 0.05385559, -0.20527905, -0.19967043, ...,  0.48037067,\n",
       "         0.91894266, -0.54557519],\n",
       "       [-1.58845638,  0.05823702, -0.46339556, ...,  1.2611837 ,\n",
       "         0.55581431, -1.1208628 ],\n",
       "       [-0.48648791, -0.79444802,  0.18657702, ...,  0.52738795,\n",
       "         0.239182  , -0.11716399]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_embeddings_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 100])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collusion\n",
      "incredible\n",
      "friday\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'democrats wrote to the ukrainian government in may urging it to continue investigations into president donald trumps alleged collusion with russia in the presidential campaign collusion later found not to exist '"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = 1000\n",
    "\n",
    "embedding = model.in_embed\n",
    "embed_vectors = embedding.weight\n",
    "magnitudes = embed_vectors.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
    "tweet_after = daily_tweets.tweets[daily_tweets.after4_date >= pd.to_datetime('1-1-2017')]\n",
    "valid_vector = torch.FloatTensor(tweet_embeddings[tw])\n",
    "wds = (torch.matmul(valid_vector, embed_vectors.t()) / torch.FloatTensor(magnitudes)).topk(10)\n",
    "for wd in list(wds[1][0].numpy()):\n",
    "    if wd> 100 :\n",
    "        print(int_to_vocab[wd])\n",
    "tweet_after[tw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23.3585,  0.0000, 21.8033,  ..., 12.9470, 15.9481, 14.7619]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([[32.8715, 28.3099, 28.2627, 27.8419, 27.8317, 27.8011, 27.7800, 27.6092,\n",
      "         27.5333, 27.5282]]),\n",
      "indices=tensor([[1467, 1673, 1574, 1575, 1200, 5555, 4169, 2394, 6768, 1474]]))\n",
      "the federal reserve loves watching our manufacturers struggle with their exports to the benefit of other parts of the world has anyone looked at what almost all other countries are doing to take advantage of the good old usa our fed has been calling it wrong for too long \n",
      "\n",
      "spread is way too much as other countries say thank you to clueless jay powell and the federal reserve germany and many others are playing the game crazy inverted yield curve we should easily be reaping big rewards amp gains but the fed is holding us back we will win \n",
      "\n",
      "doing great with china and other trade deals the only problem we have is jay powell and the fed hes like a golfer who cant putt has no touch big u s growth if he does the right thing big cut but dont count on him so far he has called it wrong and only let us down \n",
      "\n",
      "we are competing with many countries that have a far lower interest rate and we should be lower than them yesterday highest dollar in u s history no inflation wake up federal reserve such growth potential almost like never before \n",
      "\n",
      "in a hypothetical poll done by one of the worst pollsters of them all the amazon washington post abc which predicted i would lose to crooked hillary by points how did that work out sleepy joe pocahontas and virtually all others would beat me in the general election \n",
      "\n",
      "hillary clinton clearly got a pass by the fbi we have the unfortunate situation where they then decided they were going to frame donald trump concerning the rigged witch hunt joe digenova former u s attorney \n",
      "\n",
      "the united states treasury has taken in many billions of dollars from the tariffs we are charging china and other countries that have not treated us fairly in the meantime we are doing well in various trade negotiations currently going on at some point this had to be done \n",
      "\n",
      "despite a federal reserve that doesnt know what it is doing raised rates far too fast very low inflation other parts of world slowing lowering amp easing amp did large scale tightening billion month we are on course to have one of the best months of june in us history \n",
      "\n",
      "honduras mexico and many other countries that the u s is very generous to sends many of their people to our country through our weak immigration policies caravans are heading here must pass tough laws and build the wall democrats allow open borders drugs and crime \n",
      "\n",
      "starting to look good for the highly respected prime minister of the italian republic giuseppi conte represented italy powerfully at the g loves his country greatly amp works well with the usa a very talented man who will hopefully remain prime minister \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tw = 1467\n",
    "\n",
    "embedding = model.in_embed\n",
    "embed_vectors = torch.FloatTensor(tweet_embeddings_np)\n",
    "magnitudes = embed_vectors.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
    "tweet_after = daily_tweets.tweets[daily_tweets.after4_date >= pd.to_datetime('1-1-2017')]\n",
    "valid_vector = torch.FloatTensor(tweet_embeddings[tw])\n",
    "wds = (torch.matmul(valid_vector, embed_vectors.t()) / torch.FloatTensor(magnitudes))\n",
    "wds[wds != wds] = 0\n",
    "print(wds.topk(10))\n",
    "for i in wds.topk(10).indices.numpy():\n",
    "    for tweet_range in i:\n",
    "        print(tweet_after[tweet_range])\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tonight we forcefully condemn the blatant corruption of the democrat party the fake news media and the rogue bureaucrats of the deep state the only message these radicals will understand is a crushing defeat on november \n",
      "\n",
      "became number in world amp independent in energy will soon have record number of judges sc justices done more than any president in first years despite phony amp fraudulent witch hunt illegally led against him win on mueller report mueller testimony amp james comey \n",
      "\n",
      "congratulations to maxine waters whose crazy rants have made her together with nancy pelosi the unhinged face of the democrat party together they will make america weak again but have no fear america is now stronger than ever before and im not going anywhere \n",
      "\n",
      "the fake news media keeps saying we havent built any new wall below is a section just completed on the border anti climbing feature included very high strong and beautiful also many miles already renovated and in service \n",
      "\n",
      "why didnt robert mueller amp his band of angry democrats spend any time investigating crooked hillary clinton lyin amp leakin james comey lisa page and her psycho lover peter s andy mccabe the beautiful ohr family fusion gps and many more including himself amp andrew w \n",
      "\n",
      "iihan omar a member of aoc plus will win us the great state of minnesota the new face of the democrat party \n",
      "\n",
      "we cannot allow all of these people to invade our country when somebody comes in we must immediately with no judges or court cases bring them back from where they came our system is a mockery to good immigration policy and law and order most children come without parents \n",
      "\n",
      "sorry i dont buy rep tlaibs tears i have watched her violence craziness and most importantly words for far too long now tears she hates israel and all jewish people she is an anti semite she and her friends are the new face of the democrat party live with it \n",
      "\n",
      "as a candidate i promised we would pass a massive tax cut for the everyday working americans if you make your voices heard this moment will be forever remembered as a great new beginning the dawn of a brilliant american future shining with patriotism prosperity and pride \n",
      "\n",
      "the white house correspondents dinner was a failure last year but this year was an embarrassment to everyone associated with it the filthy comedian totally bombed couldnt even deliver her lines much like the seth meyers weak performance put dinner to rest or start over \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my daughter ivanka will be on tonight on at p m following the great at enjoy '"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tweet_after[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my daughter ivanka has been treated so unfairly by she is a great person always pushing me to do the right thing terrible '"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_after[9335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'will be interviewed tonight by on at p m eastern enjoy '"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_after[4955]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i will be interviewed live tonight by on p m enjoy '"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_after[2434]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs109]",
   "language": "python",
   "name": "conda-env-cs109-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
